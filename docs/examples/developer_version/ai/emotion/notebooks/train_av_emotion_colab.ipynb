{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AV Emotion Training on Colab\n",
        "\n",
        "This notebook clones your private repo, initializes the audiovisual emotion submodule, preprocesses RAVDESS, and trains a multimodal model. Replace placeholders as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Setup: clone your private repo and init submodule ---\n",
        "REPO_URL = \"https://github.com/<org-or-user>/schizodot-ai-dot.git\"  # If private, use a token URL\n",
        "!git clone $REPO_URL repo\n",
        "%cd /content/repo\n",
        "!git submodule update --init --recursive\n",
        "\n",
        "# Optional: checkout dev branch\n",
        "!git checkout dev || echo 'dev branch may already be active'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Install dependencies from the upstream audiovisual repo ---\n",
        "!pip install -r external/emotion-av/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Mount Google Drive to access RAVDESS data ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_ON_DRIVE = \"/content/drive/MyDrive/data/RAVDESS\"  # change to your path\n",
        "!mkdir -p /content/data\n",
        "!ln -s \"$DATA_ON_DRIVE\" /content/data/RAVDESS || echo 'symlink exists'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing\n",
        "Run the upstream scripts to extract face clips and audio, then build the annotations file. Adjust script names and flags to match the upstream repo if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Preprocess: examples; adjust to the actual scripts in external/emotion-av ---\n",
        "!python external/emotion-av/ravdess_preprocessing/extract_faces.py --data_root /content/data/RAVDESS || echo 'adjust script path if needed'\n",
        "!python external/emotion-av/ravdess_preprocessing/extract_audios.py --data_root /content/data/RAVDESS || echo 'adjust script path if needed'\n",
        "!python external/emotion-av/ravdess_preprocessing/create_annotations.py --data_root /content/data/RAVDESS --out /content/data/RAVDESS/annotations.txt || echo 'adjust script path if needed'\n",
        "!head -n 5 /content/data/RAVDESS/annotations.txt || echo 'annotations not ready yet'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n",
        "Choose a fusion mode. Example: `ia` stands for intermediate attention. Check the upstream README for options and best settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RESULTS_DIR = \"/content/outputs/av_emotion\"\n",
        "!mkdir -p $RESULTS_DIR\n",
        "!python external/emotion-av/main.py \\\n",
        "  --fusion ia \\\n",
        "  --annotation_path /content/data/RAVDESS/annotations.txt \\\n",
        "  --result_path $RESULTS_DIR || echo 'adjust args to match upstream main.py'\n",
        "\n",
        "!ls -la $RESULTS_DIR || true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the best checkpoint into your repo\n",
        "You can keep it on Drive or commit with Git LFS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p ai/emotion/weights\n",
        "!cp $RESULTS_DIR/*best*.pt ai/emotion/weights/av_emotion_best.pt || echo 'best checkpoint not found yet'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: commit weights using Git LFS\n",
        "If your repo is private, authenticate with a token. Otherwise skip and store weights on Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git lfs install\n",
        "!git config user.email \"you@example.com\"\n",
        "!git config user.name \"Your Name\"\n",
        "!git add ai/emotion/weights/av_emotion_best.pt || true\n",
        "!git commit -m \"model: add AV emotion checkpoint\" || true\n",
        "!git push origin dev || echo 'push skipped or not authenticated'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}